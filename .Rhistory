(!any(length(data_cols) %in% C(10,12)))
!any(length(data_cols) %in% c(10,12))
(!any(length(data_cols) %in% c(10,12)))
(!any(length(data_cols) %in% C(10,12)))
(!any(length(data_cols) %in% C(10,12)))
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
LOGGED_IN_USER_ID <- 1
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
LOGGED_IN_USER_ID <- 1
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
LOGGED_IN_USER_ID <- 1
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
?is.Date
library(lubridate)
?is.Date
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
data_cols
?gsub
gsub("\\."," ",data_cols)
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
cities
length(cities)
data.frame(a=1)
z<-data.frame(a=1)
length(z)
z<-data.frame(a=1,b=2)
length(z)
#' Geocode in DB
#'
#' Geocode missing lat /lons in the database
#' @param pool The connection pool
#' @param use_sqlite Whether to use_sqlite (alternative is postgres)
#' @return the cities table in the database gets updated
#' @export
#' @import tmaptools
#' @import DBI
#' @import dplyr
get_geo <- function(city_id,q)
{
geo <- tmaptools::geocode_OSM(q,as.data.frame=F)
if (is.null(geo)) df <- data.frame(city_id=city_id,query=q,latitude=NA,longitude=NA,stringsAsFactors=F)
else df <- data.frame(city_id=city_id,query=q,latitude=geo$coords[["y"]],longitude=geo$coords[["x"]],stringsAsFactors=F)
return (df)
}
geo_code_in_db <- function(pool)
{
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
geo_cities <- NULL
if (!is.null(cities) && length(cities) > 0)
{
geo_cities <- plyr::ldply(mapply(get_geo,city_id=cities$city_id,q=paste0(cities$city_name,", ",cities$country_name),SIMPLIFY =F))
geo_errors <- subset(geo_cities,is.na(geo_cities$latitude) | is.na(geo_cities$longitude))
geo_cities <- subset(geo_cities,!is.na(geo_cities$latitude) & !is.na(geo_cities$longitude))
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),geo_cities,row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
geo_cities$error = F
geo_errors$error = T
geo_cities <- rbind(geo_cities,geo_errors)
}
poolReturn(conn)
return (geo_cities)
}
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
cities
#' Geocode in DB
#'
#' Geocode missing lat /lons in the database
#' @param pool The connection pool
#' @param use_sqlite Whether to use_sqlite (alternative is postgres)
#' @return the cities table in the database gets updated
#' @export
#' @import tmaptools
#' @import DBI
#' @import dplyr
get_geo <- function(city_id,q)
{
geo <- tmaptools::geocode_OSM(q,as.data.frame=F)
if (is.null(geo)) df <- data.frame(city_id=city_id,query=q,latitude=NA,longitude=NA,stringsAsFactors=F)
else df <- data.frame(city_id=city_id,query=q,latitude=geo$coords[["y"]],longitude=geo$coords[["x"]],stringsAsFactors=F)
return (df)
}
geo_code_in_db <- function(pool)
{
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
geo_cities <- NULL
if (!is.null(cities) && length(cities) > 0)
{
geo_cities <- plyr::ldply(mapply(get_geo,city_id=cities$city_id,q=paste0(cities$city_name,", ",cities$country_name),SIMPLIFY =F))
geo_errors <- subset(geo_cities,is.na(geo_cities$latitude) | is.na(geo_cities$longitude))
geo_cities <- subset(geo_cities,!is.na(geo_cities$latitude) & !is.na(geo_cities$longitude))
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),geo_cities,row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
geo_cities$error = F
geo_errors$error = T
geo_cities <- rbind(geo_cities,geo_errors)
}
poolReturn(conn)
return (geo_cities)
}
conn <- poolCheckout(pool)
x<-geo_code_in_db(pool)
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
geo_cities <- NULL
if (!is.null(cities) && length(cities) > 0)
x<-geo_code_in_db(pool)true
if (!is.null(cities) && length(cities) > 0)
true
if (!is.null(cities) && length(cities) > 0)
T
geo_cities <- plyr::ldply(mapply(get_geo,city_id=cities$city_id,q=paste0(cities$city_name,", ",cities$country_name),SIMPLIFY =F))
geo_cities
geo_errors <- subset(geo_cities,is.na(geo_cities$latitude) | is.na(geo_cities$longitude))
geo_cities <- subset(geo_cities,!is.na(geo_cities$latitude) & !is.na(geo_cities$longitude))
geo_errors
geo_cities
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),geo_cities,row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
geo_cities$error = F
geo_errors$error = T
?subset
#' Geocode in DB
#'
#' Geocode missing lat /lons in the database
#' @param pool The connection pool
#' @param use_sqlite Whether to use_sqlite (alternative is postgres)
#' @return the cities table in the database gets updated
#' @export
#' @import tmaptools
#' @import DBI
#' @import dplyr
get_geo <- function(city_id,q)
{
geo <- tmaptools::geocode_OSM(q,as.data.frame=F)
if (is.null(geo)) df <- data.frame(city_id=city_id,query=q,latitude=NA,longitude=NA,stringsAsFactors=F)
else df <- data.frame(city_id=city_id,query=q,latitude=geo$coords[["y"]],longitude=geo$coords[["x"]],stringsAsFactors=F)
return (df)
}
geo_code_in_db <- function(pool)
{
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
geo_cities <- NULL
if (!is.null(cities) && length(cities) > 0)
{
geo_cities <- plyr::ldply(mapply(get_geo,city_id=cities$city_id,q=paste0(cities$city_name,", ",cities$country_name),SIMPLIFY =F))
geo_cities$error = F
geo_cities$error[is.na(geo_cities$latitude) | is.na(geo_cities$longitude)] <- T
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),geo_cities,row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
}
poolReturn(conn)
return (geo_cities)
}
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
upload_results
upload_results
upload_results[1,]
upload_results[1,] <- NA
upload_results[1,]
source('C:/Users/SHeitmann/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash/R/upload_raw_data.R')
for(i in 1:length(functions))
true
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
`{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
upload_results
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
conn <- poolCheckout(pool)
cities <- dbGetQuery(conn,"select city_id,city_name,country_name from pd_wbgtravel.cities where latitude is null or longitude is null or ceiling(latitude*100) = floor(latitude*100) or ceiling(longitude*100)=floor(longitude*100)")
cities
geo_cities <- NULL
geo_cities <- plyr::ldply(mapply(get_geo,city_id=cities$city_id,q=paste0(cities$city_name,", ",cities$country_name),SIMPLIFY =F))
geo_cities
geo_cities
geo_cities$error = F
geo_cities$error[is.na(geo_cities$latitude) | is.na(geo_cities$longitude)] <- T
geo_cities
geo_cities$error = F
geo_cities$error[is.na(geo_cities$latitude) | is.na(geo_cities$longitude)] <- T
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),subset(geo_cities,error=F),row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
geo_cities <- plyr::ldply(mapply(get_geo,city_id=cities$city_id,q=paste0(cities$city_name,", ",cities$country_name),SIMPLIFY =F))
geo_cities$error = F
geo_cities$error[is.na(geo_cities$latitude) | is.na(geo_cities$longitude)] <- T
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),subset(geo_cities,error==F),row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
geo_cities
subset(geo_cities,error==F)
dbWriteTable(conn,c("public","_temp_city_uploads"),subset(geo_cities,error==F),row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
geo_uploads <- subset(geo_cities,error==F)
if (length(geo_uploads) > 0)
{
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),geo_uploads,row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
}
geo_uploads <- subset(geo_cities,error==F)
geo_uploads
length(geo_uploads)
nrow(geo_uploads)
geo_uploads <- subset(geo_cities,error==F)
if (nrow(geo_uploads) > 0)
{
dbSendQuery(conn,"drop table if exists public._temp_city_uploads;")
dbWriteTable(conn,c("public","_temp_city_uploads"),geo_uploads,row.names=F,temporary=T)
dbSendQuery(conn,"ALTER TABLE public._temp_city_uploads ADD PRIMARY KEY (city_id);")
dbSendQuery(conn,"update pd_wbgtravel.cities set latitude=public._temp_city_uploads.latitude,	  longitude =public._temp_city_uploads.longitude from public._temp_city_uploads where _temp_city_uploads.city_id = cities.city_id;")
dbSendQuery(conn,"drop table public._temp_city_uploads;")
}
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
