#it just generates the next value on its own
# Submit the update query and disconnect
dbSendQuery(pcon, query, params=data$message) #Changed from dbGetQuery to dbSendQuery
dbDisconnect(pcon)
}
loadData <- function() {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the fetching query
query <- sprintf("SELECT * FROM testing.rw_messages", table) #changed to 'testing.rw_messages' as the schema name was missing
# Submit the fetch query and disconnect
data <- dbGetQuery(pcon, query)
dbDisconnect(pcon)
data
}
# Whenever a field is filled, aggregate all form data
formData <- reactive({
data <- sapply(fields, function(x) input[[x]])
data
})
# When the Submit button is clicked, save the form data
observeEvent(input$submit, {
saveData(formData())
})
# Show the previous responses
# (update with current response when Submit is clicked)
output$responses <- DT::renderDataTable({
input$submit
loadData()
})
}
)
# Oleksiy Anokhin
# January 14, 2018
# Set libraries
library(RPostgreSQL)
library(shiny)
# Define the fields we want to save from the form
fields <- c("id", "message")
# Shiny app with two fields that the user can submit data for
shinyApp(
ui = fluidPage(
DT::dataTableOutput("responses", width = 300), tags$hr(),
textInput("id", "ID", ""),
textInput("message", "MESSAGE", ""),
actionButton("submit", "Submit")
),
server = function(input, output, session) {
psql <- dbDriver("PostgreSQL")
saveData <- function(data) {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the update query by looping over the data fields
query <- paste0("INSERT INTO testing.rw_messages (message) VALUES ( $1 )") #Changed to a parameterized query.  Read-up on "SQL Injection Attacks"
#using names(data) is ok, in principle.  But here names gives id,message
#and while that's true these are the table's columns, the id in this case is an
#auto-incrementing value that we don't set with the insert.  We leave it blank and
#it just generates the next value on its own
# Submit the update query and disconnect
dbSendQuery(pcon, query, params=data[["message"]]) #Changed from dbGetQuery to dbSendQuery
dbDisconnect(pcon)
}
loadData <- function() {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the fetching query
query <- sprintf("SELECT * FROM testing.rw_messages", table) #changed to 'testing.rw_messages' as the schema name was missing
# Submit the fetch query and disconnect
data <- dbGetQuery(pcon, query)
dbDisconnect(pcon)
data
}
# Whenever a field is filled, aggregate all form data
formData <- reactive({
data <- sapply(fields, function(x) input[[x]])
data
})
# When the Submit button is clicked, save the form data
observeEvent(input$submit, {
saveData(formData())
})
# Show the previous responses
# (update with current response when Submit is clicked)
output$responses <- DT::renderDataTable({
input$submit
loadData()
})
}
)
# Oleksiy Anokhin
# January 14, 2018
# Set libraries
library(RPostgreSQL)
library(shiny)
# Define the fields we want to save from the form
fields <- c("id", "message")
# Shiny app with two fields that the user can submit data for
shinyApp(
ui = fluidPage(
DT::dataTableOutput("responses", width = 300), tags$hr(),
textInput("id", "ID", ""),
textInput("message", "MESSAGE", ""),
actionButton("submit", "Submit")
),
server = function(input, output, session) {
psql <- dbDriver("PostgreSQL")
saveData <- function(data) {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the update query by looping over the data fields
query <- paste0("INSERT INTO testing.rw_messages (message) VALUES ( $1 )") #Changed to a parameterized query.  Read-up on "SQL Injection Attacks"
#using names(data) is ok, in principle.  But here names gives id,message
#and while that's true these are the table's columns, the id in this case is an
#auto-incrementing value that we don't set with the insert.  We leave it blank and
#it just generates the next value on its own
# Submit the update query and disconnect
dbSendQuery(pcon, query, params=data[["message"]]) #Changed from dbGetQuery to dbSendQuery
dbDisconnect(pcon)
}
loadData <- function() {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the fetching query
query <- sprintf("SELECT * FROM testing.rw_messages", table) #changed to 'testing.rw_messages' as the schema name was missing
# Submit the fetch query and disconnect
data <- dbGetQuery(pcon, query)
dbDisconnect(pcon)
data
}
# Whenever a field is filled, aggregate all form data
formData <- reactive({
data <- sapply(fields, function(x) input[[x]])
data
})
# When the Submit button is clicked, save the form data
observeEvent(input$submit, {
saveData(formData())
})
# Show the previous responses
# (update with current response when Submit is clicked)
output$responses <- DT::renderDataTable({
input$submit
loadData()
})
}
)
# Oleksiy Anokhin
# January 14, 2018
# Set libraries
library(RPostgreSQL)
library(shiny)
# Define the fields we want to save from the form
fields <- c("id", "message")
# Shiny app with two fields that the user can submit data for
shinyApp(
ui = fluidPage(
DT::dataTableOutput("responses", width = 300), tags$hr(),
textInput("id", "ID", ""),
textInput("message", "MESSAGE", ""),
actionButton("submit", "Submit")
),
server = function(input, output, session) {
psql <- dbDriver("PostgreSQL")
saveData <- function(data) {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the update query by looping over the data fields
query <- paste0("INSERT INTO testing.rw_messages (message) VALUES ( $1 )") #Changed to a parameterized query.  Read-up on "SQL Injection Attacks"
#using names(data) is ok, in principle.  But here names gives id,message
#and while that's true these are the table's columns, the id in this case is an
#auto-incrementing value that we don't set with the insert.  We leave it blank and
#it just generates the next value on its own
# Submit the update query and disconnect
dbSendQuery(pcon, query, params=data[["message"]]) #Changed from dbGetQuery to dbSendQuery
dbDisconnect(pcon)
}
loadData <- function() {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the fetching query
query <- sprintf("SELECT * FROM testing.rw_messages", table) #changed to 'testing.rw_messages' as the schema name was missing
# Submit the fetch query and disconnect
data <- dbGetQuery(pcon, query)
dbDisconnect(pcon)
data
}
# Whenever a field is filled, aggregate all form data
formData <- reactive({
data <- sapply(fields, function(x) input[[x]])
data
})
# When the Submit button is clicked, save the form data
observeEvent(input$submit, {
saveData(formData())
})
# Show the previous responses
# (update with current response when Submit is clicked)
output$responses <- DT::renderDataTable({
input$submit
loadData()
})
}
)
# Oleksiy Anokhin
# January 14, 2018
# Set libraries
library(RPostgreSQL)
library(shiny)
# Define the fields we want to save from the form
fields <- c("id", "message")
# Shiny app with two fields that the user can submit data for
shinyApp(
ui = fluidPage(
DT::dataTableOutput("responses", width = 300), tags$hr(),
textInput("id", "ID", ""),
textInput("message", "MESSAGE", ""),
actionButton("submit", "Submit")
),
server = function(input, output, session) {
psql <- dbDriver("PostgreSQL")
saveData <- function(data) {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the update query by looping over the data fields
query <- paste0("INSERT INTO testing.rw_messages (message) VALUES ( $1 )") #Changed to a parameterized query.  Read-up on "SQL Injection Attacks"
#using names(data) is ok, in principle.  But here names gives id,message
#and while that's true these are the table's columns, the id in this case is an
#auto-incrementing value that we don't set with the insert.  We leave it blank and
#it just generates the next value on its own.  It looks like in the Navicat you entered
#ID numbers manually.  This caused it not to auto-increment and resulted in a discrepancy between the
#next auto-incremental value and the value manually entered already
# Submit the update query and disconnect
dbSendQuery(pcon, query, params=data[["message"]]) #Changed from dbGetQuery to dbSendQuery
dbDisconnect(pcon)
}
loadData <- function() {
# Connect to the database
pcon <- dbConnect(psql, dbname = "ARL", host = "w0lxsfigssa01", port = 5432, user = "rscript", password = "rscript")
# Construct the fetching query
query <- sprintf("SELECT * FROM testing.rw_messages") #changed to 'testing.rw_messages' as the schema name was missing
# Submit the fetch query and disconnect
data <- dbGetQuery(pcon, query)
dbDisconnect(pcon)
data
}
# Whenever a field is filled, aggregate all form data
formData <- reactive({
data <- sapply(fields, function(x) input[[x]])
data
})
# When the Submit button is clicked, save the form data
observeEvent(input$submit, {
saveData(formData())
})
# Show the previous responses
# (update with current response when Submit is clicked)
output$responses <- DT::renderDataTable({
input$submit
loadData()
})
}
)
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
upload_results
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
//file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
//file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
# Should be run from parent directory (traveldash)
library(openxlsx)
library(RPostgreSQL)
library(yaml)
library(DBI)
library(pool)
library(lubridate)
# Define whether on Joe's computer (dev) or elsewhere (prod)
joe <- grepl('joebrew', getwd())
if(joe){
dir <- getwd()
} else {
dir <- paste0(dirname(path.expand("~")),"/WBG/Sinja Buri - FIG SSA MEL/MEL Program Operations/Knowledge Products/Dashboards & Viz/WBG Travel/GitHub/traveldash")
setwd(dir)
}
# Source helper files
functions <- dir('R')
for(i in 1:length(functions))
{
if (functions[i]=="test_upload.R") next
else source(paste0('R/', functions[i]), chdir = TRUE)
}
pool <- create_pool(options_list = credentials_extract(),F)
file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA Feb-15.xlsx")
##file <- paste0(getwd(),"/dev_database/Travel Event Dashboard_DATA_20 Feb.xlsx")
data <- read.xlsx(file,sheet=1,startRow=2,detectDates=F)
LOGGED_IN_USER_ID <- 1
start_time <- Sys.time()
upload_results <- upload_raw_data(pool=pool,data=data,logged_in_user_id=LOGGED_IN_USER_ID,return_upload_results = TRUE)
end_time <- Sys.time()
print(paste0("Database upload time: ", end_time - start_time))
